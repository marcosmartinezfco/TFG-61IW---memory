\chapter{Results}
\label{res:resultados}

Stock price forecasting is an interesting field of application of \gls{ai} given the intrinsic correlation between statistics and financial markets. Computers are extremely efficient at recognizing patterns, thus they can identify price trends and patterns that may be embedded in in an asset's price history. Nonetheless, as we discussed in the introduction section \ref{ch:introduccion}, it is a naive approach to believe that the future can be entirely predicted based on the past. Multiple conjoined factors all together, some of which may be variable, drive the price of an asset.

This hypothesis is backed by the results obtained during the development of section \ref{NN definition} where both the \gls{mlp} model and the \gls{lstm} model presented high levels of overfitting and mode collapse around the overall average price range of the trading history of GOOGLE. The first one had a better performance overall and didn't present as much mode collapse whereas the \gls{lstm} network didnÂ´t made any learning no matter what configuration or regularization was applied. In the end the interpolation approach, which was intended to be the baseline model, ended up being the one with the highest accuracy whereas the \glspl{ann} struggled to learn meaningful patterns in the price history of GOOGLE. Better training processes and more meaningful, complete and price-relevant market information would be needed.

Regarding deployment, during section \ref{SoA:estado del arte} we discovered how the microservices architecture along with containerization techniques can establish a highly scalable architectural pattern. Throughout the entire thesis we have focused on merging these two technologies to get an overall understanding. However, there is one key concept you may have noticed which has not been the main focus during development, concurrency. Concurrency is a extremely important aspect since all the advantages provided by our architecture can not be fully exploited without it. Although some parts of the architecture support concurrency, like the prediction module \ref{prediction-module}, other parts such as the socket communication protocol between the \gls{api} Gateway and the Data Pipeline modules make use of blocking methods, restricting throughput. Nonetheless, the use of technologies such as Docker, the microservices pattern and \gls{cd} strategies have made it possible to set up a development environment with an extremely low delay between code and deployment with almost every process being automated.
